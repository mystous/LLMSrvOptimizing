INFO 06-28 04:19:03 [__init__.py:243] Automatically detected platform cuda.
Namespace(backend='vllm', base_url='http://127.0.0.1:8000', host='127.0.0.1', port=8000, endpoint='/v1/completions', dataset_name='random', dataset_path=None, max_concurrency=90, model='deepseek-ai/DeepSeek-R1-Distill-Llama-70B', tokenizer=None, use_beam_search=False, num_prompts=200, logprobs=None, request_rate=inf, burstiness=1.0, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=True, save_detailed=False, append_result=False, metadata=['input_len=1024', 'output_len=512', 'serving=dynamo_sglang'], result_dir='gpu_log', result_filename=None, ignore_eos=False, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, custom_output_len=256, custom_skip_chat_template=False, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=1024, random_output_len=512, random_range_ratio=0.0, random_prefix_len=0, hf_subset=None, hf_split=None, hf_output_len=None, top_p=None, top_k=None, min_p=None, temperature=None, tokenizer_mode='auto', served_model_name=None, lora_modules=None)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: inf
Burstiness factor: 1.0 (Poisson process)
Maximum request concurrency: 90
  0%|          | 0/200 [00:00<?, ?it/s]  0%|          | 1/200 [00:02<07:51,  2.37s/it]  1%|          | 2/200 [00:02<03:47,  1.15s/it]  2%|▏         | 3/200 [00:02<02:16,  1.45it/s]  2%|▏         | 4/200 [00:03<02:12,  1.48it/s]  2%|▎         | 5/200 [00:03<01:32,  2.11it/s]  3%|▎         | 6/200 [00:04<01:56,  1.67it/s]  4%|▎         | 7/200 [00:04<01:49,  1.76it/s]  5%|▌         | 10/200 [00:05<01:01,  3.07it/s]  6%|▌         | 11/200 [00:05<00:59,  3.16it/s]  6%|▌         | 12/200 [00:05<00:52,  3.56it/s]  8%|▊         | 15/200 [00:06<00:34,  5.32it/s]  8%|▊         | 16/200 [00:06<00:35,  5.24it/s]  9%|▉         | 18/200 [00:06<00:28,  6.28it/s] 10%|▉         | 19/200 [00:06<00:37,  4.87it/s] 10%|█         | 20/200 [00:07<00:37,  4.78it/s] 11%|█         | 22/200 [00:07<00:33,  5.25it/s] 12%|█▏        | 23/200 [00:07<00:42,  4.18it/s] 14%|█▎        | 27/200 [00:08<00:28,  5.99it/s] 16%|█▌        | 32/200 [00:08<00:17,  9.88it/s] 17%|█▋        | 34/200 [00:08<00:15, 10.49it/s] 18%|█▊        | 36/200 [00:09<00:26,  6.12it/s] 18%|█▊        | 37/200 [00:09<00:27,  5.99it/s] 19%|█▉        | 38/200 [00:09<00:31,  5.19it/s] 46%|████▋     | 93/200 [00:10<00:01, 66.58it/s] 55%|█████▍    | 109/200 [00:14<00:08, 10.72it/s] 60%|██████    | 121/200 [00:15<00:07, 10.68it/s] 65%|██████▌   | 130/200 [00:16<00:06, 10.54it/s] 68%|██████▊   | 136/200 [00:17<00:05, 10.95it/s] 70%|███████   | 141/200 [00:17<00:04, 11.85it/s] 72%|███████▎  | 145/200 [00:17<00:04, 12.08it/s] 74%|███████▍  | 149/200 [00:17<00:03, 12.77it/s] 76%|███████▌  | 152/200 [00:18<00:05,  9.03it/s] 94%|█████████▍| 188/200 [00:19<00:00, 24.92it/s] 96%|█████████▌| 192/200 [00:20<00:00, 12.99it/s] 98%|█████████▊| 195/200 [00:21<00:00, 10.53it/s] 98%|█████████▊| 197/200 [00:21<00:00, 10.12it/s]100%|█████████▉| 199/200 [00:22<00:00,  9.13it/s]100%|██████████| 200/200 [00:22<00:00,  8.88it/s]
============ Serving Benchmark Result ============
Successful requests:                     200       
Benchmark duration (s):                  22.52     
Total input tokens:                      204600    
Total generated tokens:                  88332     
Request throughput (req/s):              8.88      
Output token throughput (tok/s):         3922.57   
Total Token throughput (tok/s):          13008.25  
---------------Time to First Token----------------
Mean TTFT (ms):                          197.45    
Median TTFT (ms):                        214.03    
P99 TTFT (ms):                           291.70    
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          18.11     
Median TPOT (ms):                        18.33     
P99 TPOT (ms):                           19.82     
---------------Inter-token Latency----------------
Mean ITL (ms):                           18.35     
Median ITL (ms):                         16.30     
P99 ITL (ms):                            46.65     
==================================================
