INFO 06-30 04:40:41 [__init__.py:243] Automatically detected platform cuda.
Namespace(backend='vllm', base_url='http://127.0.0.1:8000', host='127.0.0.1', port=8000, endpoint='/v1/completions', dataset_name='random', dataset_path=None, max_concurrency=120, model='deepseek-ai/DeepSeek-R1-Distill-Llama-70B', tokenizer=None, use_beam_search=False, num_prompts=200, logprobs=None, request_rate=inf, burstiness=1.0, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=True, save_detailed=False, append_result=False, metadata=['input_len=1024', 'output_len=512', 'serving=sglang'], result_dir='gpu_log', result_filename=None, ignore_eos=False, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, custom_output_len=256, custom_skip_chat_template=False, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=1024, random_output_len=512, random_range_ratio=0.0, random_prefix_len=0, hf_subset=None, hf_split=None, hf_output_len=None, top_p=None, top_k=None, min_p=None, temperature=None, tokenizer_mode='auto', served_model_name=None, lora_modules=None)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: inf
Burstiness factor: 1.0 (Poisson process)
Maximum request concurrency: 120
  0%|          | 0/200 [00:00<?, ?it/s]  0%|          | 1/200 [00:01<03:21,  1.01s/it]  1%|          | 2/200 [00:01<03:04,  1.07it/s]  2%|▏         | 3/200 [00:02<01:55,  1.70it/s]  2%|▎         | 5/200 [00:02<00:57,  3.40it/s]  3%|▎         | 6/200 [00:02<00:48,  3.97it/s]  4%|▎         | 7/200 [00:02<00:45,  4.26it/s]  4%|▍         | 8/200 [00:02<00:40,  4.78it/s]  5%|▌         | 10/200 [00:02<00:33,  5.71it/s]  6%|▌         | 12/200 [00:03<00:26,  7.01it/s]  7%|▋         | 14/200 [00:03<00:24,  7.71it/s]  8%|▊         | 17/200 [00:03<00:23,  7.95it/s] 10%|█         | 20/200 [00:04<00:20,  8.84it/s] 10%|█         | 21/200 [00:04<00:32,  5.50it/s] 11%|█         | 22/200 [00:04<00:30,  5.80it/s] 12%|█▏        | 23/200 [00:04<00:28,  6.19it/s] 12%|█▏        | 24/200 [00:04<00:29,  6.02it/s] 13%|█▎        | 26/200 [00:05<00:31,  5.57it/s] 14%|█▎        | 27/200 [00:05<00:31,  5.44it/s] 14%|█▍        | 28/200 [00:05<00:28,  5.99it/s] 14%|█▍        | 29/200 [00:06<00:56,  3.02it/s] 15%|█▌        | 30/200 [00:06<00:51,  3.28it/s] 16%|█▌        | 31/200 [00:07<01:09,  2.44it/s] 16%|█▌        | 32/200 [00:07<01:02,  2.71it/s] 16%|█▋        | 33/200 [00:08<01:37,  1.70it/s] 17%|█▋        | 34/200 [00:09<01:36,  1.73it/s] 18%|█▊        | 35/200 [00:09<01:18,  2.11it/s] 18%|█▊        | 36/200 [00:10<01:43,  1.59it/s] 51%|█████     | 102/200 [00:11<00:02, 35.61it/s] 62%|██████▎   | 125/200 [00:11<00:01, 48.91it/s] 68%|██████▊   | 135/200 [00:12<00:02, 27.14it/s] 72%|███████▏  | 143/200 [00:12<00:02, 26.27it/s] 74%|███████▍  | 149/200 [00:12<00:02, 24.80it/s] 77%|███████▋  | 154/200 [00:13<00:02, 16.55it/s] 79%|███████▉  | 158/200 [00:14<00:02, 14.40it/s] 80%|████████  | 161/200 [00:15<00:03, 10.31it/s] 82%|████████▏ | 163/200 [00:15<00:04,  7.85it/s] 82%|████████▎ | 165/200 [00:17<00:06,  5.23it/s] 84%|████████▎ | 167/200 [00:17<00:05,  5.81it/s] 84%|████████▍ | 169/200 [00:17<00:05,  5.83it/s] 85%|████████▌ | 170/200 [00:18<00:06,  4.81it/s] 86%|████████▌ | 171/200 [00:18<00:05,  4.99it/s]100%|██████████| 200/200 [00:18<00:00, 10.99it/s]
============ Serving Benchmark Result ============
Successful requests:                     200       
Benchmark duration (s):                  18.21     
Total input tokens:                      204600    
Total generated tokens:                  85529     
Request throughput (req/s):              10.99     
Output token throughput (tok/s):         4697.80   
Total Token throughput (tok/s):          15935.74  
---------------Time to First Token----------------
Mean TTFT (ms):                          661.16    
Median TTFT (ms):                        947.67    
P99 TTFT (ms):                           1098.73   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          17.87     
Median TPOT (ms):                        18.83     
P99 TPOT (ms):                           23.17     
---------------Inter-token Latency----------------
Mean ITL (ms):                           17.78     
Median ITL (ms):                         16.54     
P99 ITL (ms):                            62.03     
==================================================
