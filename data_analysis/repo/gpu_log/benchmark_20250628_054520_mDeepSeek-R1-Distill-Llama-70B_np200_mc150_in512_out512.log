INFO 06-28 05:45:25 [__init__.py:243] Automatically detected platform cuda.
Namespace(backend='vllm', base_url='http://127.0.0.1:8000', host='127.0.0.1', port=8000, endpoint='/v1/completions', dataset_name='random', dataset_path=None, max_concurrency=150, model='deepseek-ai/DeepSeek-R1-Distill-Llama-70B', tokenizer=None, use_beam_search=False, num_prompts=200, logprobs=None, request_rate=inf, burstiness=1.0, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=True, save_detailed=False, append_result=False, metadata=['input_len=512', 'output_len=512', 'serving=dynamo_sglang'], result_dir='gpu_log', result_filename=None, ignore_eos=False, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, custom_output_len=256, custom_skip_chat_template=False, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=512, random_output_len=512, random_range_ratio=0.0, random_prefix_len=0, hf_subset=None, hf_split=None, hf_output_len=None, top_p=None, top_k=None, min_p=None, temperature=None, tokenizer_mode='auto', served_model_name=None, lora_modules=None)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: inf
Burstiness factor: 1.0 (Poisson process)
Maximum request concurrency: 150
  0%|          | 0/200 [00:00<?, ?it/s]  0%|          | 1/200 [00:02<08:31,  2.57s/it]  1%|          | 2/200 [00:02<04:08,  1.25s/it]  2%|▏         | 3/200 [00:03<02:47,  1.18it/s]  2%|▎         | 5/200 [00:03<01:30,  2.16it/s]  4%|▎         | 7/200 [00:03<00:55,  3.47it/s]  4%|▍         | 9/200 [00:03<00:41,  4.60it/s]  5%|▌         | 10/200 [00:04<00:57,  3.32it/s]  6%|▌         | 12/200 [00:04<00:49,  3.83it/s]  6%|▋         | 13/200 [00:05<00:52,  3.55it/s]  7%|▋         | 14/200 [00:05<00:54,  3.44it/s]  8%|▊         | 15/200 [00:05<00:50,  3.65it/s]  8%|▊         | 16/200 [00:06<01:00,  3.05it/s] 11%|█         | 22/200 [00:06<00:23,  7.50it/s] 12%|█▏        | 23/200 [00:06<00:27,  6.48it/s] 12%|█▏        | 24/200 [00:07<00:30,  5.80it/s] 13%|█▎        | 26/200 [00:07<00:24,  7.06it/s] 14%|█▍        | 28/200 [00:07<00:20,  8.28it/s] 14%|█▍        | 29/200 [00:07<00:24,  7.10it/s] 15%|█▌        | 30/200 [00:07<00:24,  6.98it/s] 16%|█▌        | 32/200 [00:08<00:26,  6.33it/s] 17%|█▋        | 34/200 [00:08<00:32,  5.17it/s] 18%|█▊        | 35/200 [00:08<00:30,  5.44it/s] 18%|█▊        | 36/200 [00:09<00:40,  4.01it/s] 19%|█▉        | 38/200 [00:09<00:33,  4.89it/s] 20%|██        | 40/200 [00:09<00:27,  5.85it/s] 20%|██        | 41/200 [00:09<00:26,  6.01it/s] 22%|██▎       | 45/200 [00:10<00:14, 10.43it/s] 24%|██▎       | 47/200 [00:10<00:22,  6.66it/s] 26%|██▌       | 51/200 [00:10<00:16,  8.95it/s] 27%|██▋       | 54/200 [00:11<00:15,  9.57it/s] 28%|██▊       | 56/200 [00:11<00:13, 10.66it/s] 29%|██▉       | 58/200 [00:11<00:13, 10.62it/s] 78%|███████▊  | 155/200 [00:11<00:00, 140.70it/s] 86%|████████▌ | 171/200 [00:14<00:01, 24.00it/s]  91%|█████████ | 182/200 [00:16<00:00, 19.55it/s] 95%|█████████▌| 190/200 [00:17<00:00, 15.96it/s] 98%|█████████▊| 196/200 [00:17<00:00, 16.16it/s]100%|██████████| 200/200 [00:17<00:00, 11.25it/s]
============ Serving Benchmark Result ============
Successful requests:                     200       
Benchmark duration (s):                  17.78     
Total input tokens:                      102200    
Total generated tokens:                  89911     
Request throughput (req/s):              11.25     
Output token throughput (tok/s):         5058.02   
Total Token throughput (tok/s):          10807.36  
---------------Time to First Token----------------
Mean TTFT (ms):                          284.24    
Median TTFT (ms):                        342.61    
P99 TTFT (ms):                           378.75    
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          20.61     
Median TPOT (ms):                        21.90     
P99 TPOT (ms):                           22.79     
---------------Inter-token Latency----------------
Mean ITL (ms):                           21.50     
Median ITL (ms):                         18.66     
P99 ITL (ms):                            72.42     
==================================================
