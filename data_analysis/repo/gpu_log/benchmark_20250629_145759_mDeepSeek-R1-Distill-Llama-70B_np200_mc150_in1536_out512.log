INFO 06-29 14:58:04 [__init__.py:243] Automatically detected platform cuda.
Namespace(backend='vllm', base_url='http://127.0.0.1:8000', host='127.0.0.1', port=8000, endpoint='/v1/completions', dataset_name='random', dataset_path=None, max_concurrency=150, model='deepseek-ai/DeepSeek-R1-Distill-Llama-70B', tokenizer=None, use_beam_search=False, num_prompts=200, logprobs=None, request_rate=inf, burstiness=1.0, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=True, save_detailed=False, append_result=False, metadata=['input_len=1536', 'output_len=512', 'serving=vllm'], result_dir='gpu_log', result_filename=None, ignore_eos=False, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, custom_output_len=256, custom_skip_chat_template=False, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=1536, random_output_len=512, random_range_ratio=0.0, random_prefix_len=0, hf_subset=None, hf_split=None, hf_output_len=None, top_p=None, top_k=None, min_p=None, temperature=None, tokenizer_mode='auto', served_model_name=None, lora_modules=None)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: inf
Burstiness factor: 1.0 (Poisson process)
Maximum request concurrency: 150
  0%|          | 0/200 [00:00<?, ?it/s]  0%|          | 1/200 [00:03<12:20,  3.72s/it]  2%|▏         | 3/200 [00:04<03:42,  1.13s/it]  2%|▏         | 4/200 [00:04<03:12,  1.02it/s]  2%|▎         | 5/200 [00:05<02:18,  1.41it/s]  3%|▎         | 6/200 [00:05<01:47,  1.81it/s]  4%|▎         | 7/200 [00:05<01:19,  2.42it/s]  4%|▍         | 8/200 [00:05<01:03,  3.01it/s]  4%|▍         | 9/200 [00:05<00:51,  3.71it/s]  6%|▌         | 11/200 [00:05<00:33,  5.73it/s]  6%|▌         | 12/200 [00:05<00:31,  5.89it/s]  7%|▋         | 14/200 [00:06<00:22,  8.20it/s]  8%|▊         | 16/200 [00:06<00:25,  7.23it/s] 10%|▉         | 19/200 [00:06<00:18,  9.53it/s] 10%|█         | 21/200 [00:07<00:29,  6.15it/s] 11%|█         | 22/200 [00:07<00:27,  6.59it/s] 12%|█▏        | 24/200 [00:07<00:22,  7.83it/s] 13%|█▎        | 26/200 [00:07<00:23,  7.36it/s] 14%|█▎        | 27/200 [00:07<00:24,  6.97it/s] 14%|█▍        | 29/200 [00:08<00:20,  8.18it/s] 15%|█▌        | 30/200 [00:08<00:21,  7.73it/s] 16%|█▌        | 31/200 [00:08<00:32,  5.27it/s] 16%|█▌        | 32/200 [00:08<00:35,  4.76it/s] 16%|█▋        | 33/200 [00:09<01:13,  2.28it/s] 17%|█▋        | 34/200 [00:10<00:58,  2.86it/s] 18%|█▊        | 35/200 [00:10<00:49,  3.30it/s] 18%|█▊        | 36/200 [00:10<00:40,  4.05it/s] 18%|█▊        | 37/200 [00:10<00:37,  4.40it/s] 19%|█▉        | 38/200 [00:10<00:45,  3.59it/s] 20%|█▉        | 39/200 [00:11<00:48,  3.33it/s] 20%|██        | 40/200 [00:11<00:57,  2.77it/s] 20%|██        | 41/200 [00:12<01:24,  1.88it/s] 21%|██        | 42/200 [00:13<01:19,  2.00it/s] 22%|██▏       | 44/200 [00:13<00:57,  2.72it/s] 22%|██▎       | 45/200 [00:14<01:03,  2.44it/s] 23%|██▎       | 46/200 [00:14<01:03,  2.43it/s] 24%|██▍       | 48/200 [00:14<00:40,  3.78it/s] 24%|██▍       | 49/200 [00:14<00:37,  4.07it/s] 25%|██▌       | 50/200 [00:14<00:31,  4.77it/s] 26%|██▌       | 51/200 [00:15<00:41,  3.63it/s] 26%|██▋       | 53/200 [00:15<00:33,  4.38it/s] 27%|██▋       | 54/200 [00:16<00:36,  3.97it/s] 29%|██▉       | 58/200 [00:17<00:42,  3.36it/s] 30%|██▉       | 59/200 [00:17<00:40,  3.52it/s] 30%|███       | 60/200 [00:17<00:37,  3.70it/s] 31%|███       | 62/200 [00:18<00:32,  4.21it/s] 46%|████▌     | 91/200 [00:18<00:03, 31.76it/s] 72%|███████▏  | 144/200 [00:18<00:00, 90.43it/s] 84%|████████▍ | 168/200 [00:18<00:00, 86.28it/s] 92%|█████████▎| 185/200 [00:20<00:00, 31.53it/s] 98%|█████████▊| 197/200 [00:23<00:00, 12.73it/s]100%|██████████| 200/200 [00:23<00:00,  8.34it/s]
============ Serving Benchmark Result ============
Successful requests:                     200       
Benchmark duration (s):                  23.99     
Total input tokens:                      307000    
Total generated tokens:                  81479     
Request throughput (req/s):              8.34      
Output token throughput (tok/s):         3396.34   
Total Token throughput (tok/s):          16193.23  
---------------Time to First Token----------------
Mean TTFT (ms):                          1612.75   
Median TTFT (ms):                        1496.15   
P99 TTFT (ms):                           3676.77   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          34.12     
Median TPOT (ms):                        31.54     
P99 TPOT (ms):                           81.74     
---------------Inter-token Latency----------------
Mean ITL (ms):                           30.63     
Median ITL (ms):                         25.05     
P99 ITL (ms):                            57.68     
==================================================
